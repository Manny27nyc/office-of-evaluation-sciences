---
layout: page
title: Evaluation Resources
permalink: /evaluationresources/
image:
image_full: 
class:
summary: OES develops resources to help agencies learn from leading evaluation practices. 
---

### Evidence Act Toolkits
Learning agendas, Annual Evaluation Plans, and the capacity assessment Toolkits are intended as resources to help agencies learn from leading practices and case studies to build a culture and infrastructure for continuous learning and improvement. <br>
<a href="https://oes.gsa.gov/toolkits/">Find more information here.</a>

### Preregistration as a Tool for Strengthening Federal Evaluation
In order to ensure that evaluation findings are reliable and that statistical results are well founded, it is essential that evaluators commit to specific design choices and analytic methods in advance. By making these details publicly available -- a practice known as preregistration -- we promote transparency and reduce the risk of inadvertently tailoring methods to obtain certain results or selectively reporting positive results. This guidance paper describes the importance and benefits of preregistration and addresses concerns that Federal evaluators might have.
<br/>
<a href="{{ '/assets/files/preregistration-as-a-tool-in-federal-evaluation.pdf' | prepend: site.baseurl }}">Preregistration handout</a>

### Evaluation Working Group Case Study
text forthcoming<br>
(insert link)

### How to Use Unexpected and Null Results
Recent research shows that null results in federal evaluations are more common than we think, and occur for a variety of reasons. When agencies share both expected and unexpected results, we can learn about what programs work, what effect sizes are realistic, and improve Federal evaluations. This post dispels misconceptions about null results and highlights different uses and lessons from null results. 
<br/>
 <a href="{{ '/assets/files/unexpected-results-2-pager.pdf' | prepend: site.baseurl }}">Unexpected results handout</a>
