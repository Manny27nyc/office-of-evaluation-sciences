---
layout: default
title: OES Methods
permalink: /methods/
image:
image_full: true
class:
summary: Because results from OES evaluations impact the lives of millions of Americans, the quality of our work is of paramount importance.
---

<div class="usa-section background-brand-dark">
  <div class="grid-container">
    <h1>{{ page.title }}</h1>
  </div>
</div>
<div class="grid-container usa-prose main-content" id="main">
  {% if page.summary %}
  <p class="billboard-message">{{ page.summary }}</p>
  {% endif %}
  {% if page.image and page.image_full %}
  <img src="{{ page.image | prepend: site.baseurl }}" alt="{{ page.image_alt_text }}">
  {% elsif page.image %}
  <div class="page--banner" style="background-image: url({{ page.image | prepend: site.baseurl }});" role="img" {% if page.image_alt_text %} aria-labelledby="caption" {% endif %}>
    {% if page.image_alt_text %}
    <p class="usa-sr-only" id="caption">{{ page.image_alt_text }}</p>
    {% endif %}
  </div>
  {% endif %}
<h1>OES Evaluation Policy & Process</h1>
<p>We follow the <a href="{{ '/assets/files/evaluationpolicy.pdf' | prepend: site.baseurl }}">OES Evaluation Policy</a> and six steps to ensure our findings are relevant and reliable.<br>
  <img src="{{ '/assets/img/oes-project-process-small.png' | prepend: site.baseurl }}" width="400"><br>
<br><a href="{{ '/projectprocess' | prepend: site.baseurl }}">Learn more about our project process here.</a></p>
  
<h1>Methods for Evaluation Design and Statistical Analysis</h1>
<p>We have produced a series of methods papers for our own team’s use in designing randomized evaluations and conducting statistical analysis. Take a look if you would like to know more about our methods. If you find these useful in your own evaluation work, or if you have questions or would like to request additional resources, please <a href="mailto:oes@gsa.gov?subject=Methods">let us know.</a></p>
  
<h2>Reporting Statistical Results in Text and in Graphs</h2>
<p>This <a href="https://oes.gsa.gov/assets/files/reporting-statistical-results.pdf">guidance paper</a> describes OES’s preferred methods for reporting statistical results from a randomized evaluation. It explains how to report a regression coefficient that estimates the effect of a treatment or intervention, as well as how to produce the graphs that OES includes in its project abstracts. Code for generating graphs, both in R and in Stata, is included.</p>
  
<h2>Blocking in Randomized Evaluations</h2>
<p>Whenever possible, we incorporate background information about individuals (or other units) into an evaluation through block randomization. This helps make our estimates of the effects of a program or intervention as precise as possible. This <a href="https://oes.gsa.gov/assets/files/block-randomization.pdf">guidance paper</a> describes OES’s approach to block randomization.</p>
  
  <h2>Calculating Standard Errors Guide</h2>
  <p> This <a href="/assets/files/calculating-standard-errors-guidance.pdf">guidance paper</a> describes OES’s preferred method for calculating parametric standard errors for OLS regressions — in particular, the reasons for using HC2 standard errors — and how to calculate them in R and Stata. OES often analyzes the results of RCTs by estimating a parametric statistical model — typically an ordinary least squares (OLS) regression — where one of the parameters represents the effect of a treatment or intervention. In order to infer whether this treatment effect is statistically significant, we typically depend on an estimate of the standard error associated with this parameter.</p>
  
  <h2>Multiple Comparison Adjustment Guide</h2>
  <p>This <a href="/assets/files/multiple-comparison-adjustment.pdf">guidance paper</a> describes OES's approach to adjusting for multiple comparisons. When evaluators run multiple statistical tests -- for example, looking at multiple possible outcomes of a program or intervention, or testing multiple versions of an intervention -- it is important to account for this when reporting and interpreting the results. </p>
  
  <h2>Preregistration in External Registries Guide</h2>
  <p>This <a href="/assets/files/preregistration-external-registries.pdf">guidance paper</a> describes the importance and benefits of preregistration and addresses concerns that Federal evaluators might have. In order to ensure that evaluation findings are reliable and that statistical results are well founded, it is essential that evaluators commit to specific design choices and analytic methods in advance. By making these details publicly available -- a practice known as preregistration -- we promote transparency and reduce the risk of inadvertently tailoring methods to obtain certain results or selectively reporting positive results.</p>
